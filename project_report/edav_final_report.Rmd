---
title: "A Visual Analysis of Data Breaches from 2005 to 2018"
author: "Michelle Chen, Yimin Wang, Jing Yi Zhou"
date: "December 8, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introduction

In light of recent data breaches to major organizations such as Facebook and more recently Marriott, companies are beginning to take extra precautions to protect their data. Data breaches are not only costly to recuperate from, but also hurt businesses and consumers in the long-run. This movement sparks great discussion about the types of companies and industries that are typically targeted, when breaches occur, how the breaches are broadcasted to the public, and just how much of our data is at stake. Using United States data breaches information from 2005 to 2018, our group hopes to craft a comprehensive story centered on these breaches and help the public better understand why they are happening through meaningful visualizations and interactivity. 

Our team consisted of Michelle Chen, Yimin Wang, and Jingyi Zhou. The delegation of tasks was as follows: We all came together to come up with a coherent story to introduce novel insights using our visualizations. Michelle was in charge of the visualizations related to the number of records breached for specific categories, states and regions. These initial visualizations helped us to establish an understanding of the distribution of records breached across various states, categories, and regions. Yimin sought to analyze the breach type attribute in depth by analyzing the frequency of specific breach types across various industries and regions. Lastly, Jingyi plotted time-series data and visualizations related to the breach source. Report-wise, we each wrote our own respective sections related to the parts of the data we worked on. Jingyi Zhou consolidated everything into a nice shiny app for presentation purposes of our visualizations and analysis.  


### Description of data

We obtained our data from theDataMap, a non-profit organization focused on documenting all the places and entities that our personal data gets transferred to and from. theDataMap operates as a research project in the Data Privacy Lab, which is a program in the Institute for Quantitative Social Science at Harvard University. Interested in seeing what types of analysis and insight students and researchers could garner about data breaches, theDataMap is hosting a competition where they have released company breach data and is asking researchers to come up with novel insights from the data. Our team chose to utilize these datasets for our EDAV final project, which can be accessed here: https://thedatamap.org/contests/materials.php. We will also be submitting our final analysis to theDataMapT's competition. We hope that our exploratory data analysis can help promote greater awareness to the academic community and our fellow classmates at Columbia University regarding where and why data breaches occur.

### Analysis of data quality

The raw data comes in the form of four files. Note that we did not use every single . They are as follows: 

**orgsindex.csv** is a list of organizations and entities whose data sharing transaction(s) appear on theDataMap. The file has 5351 rows in total, not including the header row. The fields are as follows:

* *OrgID* - A unique identifier associated with the entity.

* *Name* - The name of the entity.

* *SourceType* - The type of source from which the name appeared.

**categories.csv** is a list of categories of data holders of health data. The file has 54 rows, not including the header row. These correspond to the nodes on the graph itself. The fields are as follows:

* *CatID* - The unique identifier associated with a node on the graph.

* *CatName* - The name that appears for the node.

* *Coordinates* - The 4 pixel coordinates that locate the box associated with the node.

* *Hover* - The descriptive text that appears when the mouse hovers over the box associated with the node.

**orgsindex.csv** is a list of organizations and entities whose data sharing transaction(s) appear on theDataMap. The file has 5351 rows in total, not including the header row. The fields are as follows:

* *OrgID* - is an association list of categories (CatID) from the categories file and organizations (OrgID) from the OrgsIndex file. The file has 5336 rows, not including the header row. The fields are:

* *Type* - The kind of source that provided the information, such as "Discharge" or "Breaches".

**prcbreaches2005-18.csv** contains a list of breaches associated with different categories and organizations. The file has 4126 rows, not 
including the header row. The fields are:

* *Records.Breached* - The total number of records breached for some of the organizations.
* *Records.Breached...Detail* - The number of records breached with more details about the breaches.
* *Name* - The name of the organization.
* *CatID* - The category ID used in the other data files.
* *Total.Records* - The total number of breaches for all of the organzations (more information than Records.Breached).
* *Region* - The region that the organization is located in.
* *Contact..etc.* - The contact information for the organization.
* *Category_dm* - The name of the category associated with the CatID.
* *Entity_prc* - The type of organization.
* *State* - The state that the organization is located in.
* *OrgID* - The Organization ID.
* *Location* - The city that the organization is located in.
* *Date.Made.Public* - The date that the breaches were made public.
* *Year* - The year that the breaches were made public.
* *Source.of.Breach.Notification* - The source that publicized the breaches.
* *Type* - The type of breach.
* *Description* - The description of the breach.
* *Example (HTML)* - The HTML code used to generate the list of examples for each category in the health visualization.

#### Merging the data together

We decided to merge the four original datasets together so that we could create one final, comprehensive data set with all of the important attributes that we wanted to analyze. First, we merged prc_breaches with catorgs using the a composite key made up of cat_id and org_id. Next, we merged this intermediary data set with the categories dataset on cat_id. Lastly, we merged this output with the orgsindex dataset on org_id. Our final dataset contained 4126 rows and 19 columns.



The columns are as follows:

* Org_id (ID) - The unique identifier for the organization

* Cat_id (ID) - The unique identifier for the category of organization

* Cat_name (Categorical) - The name of the category

* Records_breached (Continuous) - The number of records breached if there were records breached. NA if no records were breached.

* Records_breached_detail (String) - Description of the records breached. NA if no description. Some rows include total number of records maintained by the organization. Some rows include a note that no SSNs were breached. Some rows include miscellaneous information.

* Name (String) - The name of the organization

* State (Categorical) - The state that the organization is in

* Total_records (Continuous) - Total number of records maintained by the organization

* Category (Categorical) - Name of the category of the organization

* Entity_type (Categorical) - Code for the entity type
  + BSO - business other
  + BSF - business - financial and insurance services
  + BSR - business - retail and merchant
  + EDU - education institutions
  + GOV - government and military
  + MED - healthcare - medical provider
  + NGO - nonprofit organizations

* Breach_source (Categorical) - The source that published the breach

* Breach_type (Categorical) - The type of breach that occurred
  + DISC - Unintended disclosure
  + HACK - Hacking
  + CARD - Payment card fraud
  + INSD - Insider
  + PHYS - Physical loss
  + PORT - Portable device loss
  + STAT - Stationary device loss
  + UNKN - Cause of breach unknown

* Region (categorical) - The region that the company is in

* Breach_id (ID) - Unique identifier for the breach

```{r}
library(data.table)
library(glue)
library(vcd)
library(tidyverse)

setwd(dirname(rstudioapi::getSourceEditorContext()$path))
parent_dir <- getwd()

dt.categories <- fread(glue("{parent_dir}/health_care_data/categories.csv"))
dt.catorgs <- fread(glue("{parent_dir}/health_care_data/catsorgs.csv"))
dt.orgsindex <- fread(glue("{parent_dir}/health_care_data/orgsindex.csv"))
dt.prcbreaches <- fread(glue("{parent_dir}/health_care_data/prcbreaches2005-18.csv"))

dt.categories_final <- dt.categories[,list(cat_id = CatID,
                                     cat_name = CatName)]

dt.catorgs_final <- dt.catorgs[,list(cat_id = CatID,
                               org_id = OrgID,
                               type = Type)]

dt.orgsindex_final <- dt.orgsindex[,list(org_id = OrgID,
                                   company_name = Name,
                                   source_type = SourceType)]

dt.prcbreaches_final <- dt.prcbreaches[,list(records_breached = Records.Breached,
                                       records_breached_detail = Records.Breached...Detail,
                                       name = Name,
                                       cat_id = CatID,
                                       total_records = Total.Records,
                                       region = Region,
                                       category = Category_dm,
                                       entity_type = Entity_prc,
                                       state = State,
                                       org_id = OrgID,
                                       location = Location,
                                       dt = Date.Made.Public,
                                       breach_source = Source.of.Breach.Notification,
                                       breach_type = Type)]

dt.orgsindex_final <- unique(dt.orgsindex_final, by = c("org_id"))

dt.master <- merge(merge(merge(dt.prcbreaches_final, dt.catorgs_final, by = c("cat_id", "org_id"), all.x = TRUE),
                   dt.categories_final, by = c("cat_id"), all.x = TRUE),
                   dt.orgsindex_final, by = c("org_id"), all.x = TRUE)

# Fix region
dt.region <- unique(dt.master[!is.na(region)][,list(region, state)])

# Merge it backc on
dt.master[,region := NULL]
dt.master <- merge(dt.master, dt.region, by = c("state"), all.x = TRUE)

# Add unique identifier to each breach
dt.master$breach_id <- 1:nrow(dt.master)

dt.date_format1 <- dt.master[grepl("\\-", dt)]
dt.date_format1$dt <- as.Date(dt.date_format1$dt, format = "%d-%b-%y")

dt.date_format2 <- dt.master[grepl("\\/", dt)]
dt.date_format2$dt <- as.Date(dt.date_format2$dt, format = "%m/%d/%Y")

dt.data <- rbind(dt.date_format1,
                  dt.date_format2)
dt.data[,dt := as.Date(dt, format = "%m/%d/%Y")]
  
# Rows where records breached is NA is assumed to be 0 
dt.data[is.na(records_breached) & total_records == 0]$records_breached <- 0
  
# Merge breach type name to data
dt.breach_type_name <- data.table(breach_type = c("DISC", "HACK", "CARD", "INSD", "PHYS", "PORT", "STAT", "UNKN"),
                                    breach_type_name = c("Unintended Disclosure",
                                                         "Hacking",
                                                         "Payment Card Fraud",
                                                         "Insider Fraud",
                                                         "Physical Loss",
                                                         "Portable Device Loss",
                                                         "Stationary Device Loss",
                                                         "Unknown"))
dt.data <- merge(dt.data, dt.breach_type_name, by = c("breach_type"))
  
# State population data retrieved from Wikipedia
dt.state_population <- fread(paste0(parent_dir, "/health_care_data/state_population.csv"))
dt.state_population[,V1 := NULL]
```


### Missing Data Analysis:

Before diving into our data visualizations, we wanted to examine the amount of missing data in our data set. We first used the mi package's missing_data.frame() function to obtain a visual of the amount of missing data for each observation/row number and a corresponding column variable. Red in the resulting chart means that there is very few or no missing data. We see that the majority of the data is present. However, the two columns, records_breached and records_breached_detail, presented a great deal of black, meaning that those cells/instances in the column have missing data. Since records_breached_detail is simply an expanded version of records_breached with additional qualitative details, from a numeric records breached perspective it is redundant and therefore the only column with a concerning amount of missing data is the records_breached continuous variable column. 

```{r}
library(mi)
x<-missing_data.frame(dt.master)
image(x)
```







